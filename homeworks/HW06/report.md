# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000 строк, 38 столбцов)
- Целевая переменная: `target` (бинарная: класс 0 - 73.7%, класс 1 - 26.3%). Сильный дисбаланс классов.
- Признаки: 37 числовых признаков (f01-f35, x_int_1, x_int_2), все непрерывные или целочисленные. Категориальных признаков нет.

## 2. Protocol

- Разбиение: train/test (75%/25%, `random_state=42`, стратификация по `target`)
- Подбор: CV на train (5 фолдов для DecisionTree, 3 фолдов для RandomForest и GradientBoosting, оптимизация ROC-AUC)
- Метрики: accuracy, F1, ROC-AUC. ROC-AUC выбран как основная метрика, так как он устойчив к дисбалансу классов и оценивает качество вероятностных предсказаний. F1-score также важен из-за дисбаланса классов.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline, стратегия 'stratified')
- LogisticRegression (baseline из S05, Pipeline со StandardScaler)
- DecisionTreeClassifier (подбирались: `max_depth` [3, 5, 7, 10, None], `min_samples_leaf` [1, 3, 5, 10], `criterion` ['gini', 'entropy'])
- RandomForestClassifier (подбирались: `n_estimators` [50, 100], `max_depth` [5, 10, None], `min_samples_leaf` [1, 3, 5], `max_features` ['sqrt', 'log2'])
- GradientBoostingClassifier (подбирались: `n_estimators` [50, 100], `learning_rate` [0.01, 0.1, 0.2], `max_depth` [3, 5], `min_samples_leaf` [1, 3])

Опционально:

- StackingClassifier (DecisionTree + RandomForest, мета-модель: LogisticRegression, 3 фолда)

## 4. Results

| Модель | Accuracy | F1-score | ROC-AUC | CV Score |
|--------|----------|----------|---------|----------|
| DummyClassifier | 0.6180 | 0.2644 | 0.5032 | N/A |
| LogisticRegression | 0.8162 | 0.5717 | 0.8009 | N/A |
| DecisionTree | 0.8238 | 0.6337 | 0.8289 | 0.8232 |
| RandomForest | 0.8893 | 0.7520 | 0.9266 | 0.9225 |
| GradientBoosting | 0.9024 | 0.7955 | 0.9282 | 0.9221 |
| Stacking | 0.9040 | 0.8036 | 0.9218 | N/A |

Победитель: **GradientBoostingClassifier** (ROC-AUC = 0.9282, F1-score = 0.7955)
Объяснение: GradientBoosting показал наилучший ROC-AUC среди всех моделей, а также высокий F1-score, что особенно важно при дисбалансе классов. Stacking показал лучший accuracy и F1-score, но немного уступил по ROC-AUC.

## 5. Analysis

- Устойчивость: При изменении `random_state` (5 прогонов) для RandomForest средний ROC-AUC = 0.9247±0.0020, что указывает на хорошую устойчивость модели. Разброс значений минимальный (0.0058), что подтверждает стабильность ансамблевых методов.
- Ошибки: Confusion matrix для GradientBoosting показывает 3207 TN, 111 FP, 328 FN, 854 TP. Модель хорошо справляется с отрицательным классом (высокий TN), но имеет умеренное количество FN (328), что может быть связано с дисбалансом классов.
- Интерпретация: Permutation importance показывает, что наиболее важные признаки: f16 (0.0787), f01 (0.0294), f07 (0.0200), f23 (0.0163), f08 (0.0155). Признак f16 значительно превосходит остальные по важности, что может указывать на его ключевую роль в разделении классов.

## 6. Conclusion

1. На данных с сильным дисбалансом классов (73.7% vs 26.3%) ансамбли (GradientBoosting, RandomForest) значительно превосходят одиночные модели по всем метрикам, особенно по F1-score и ROC-AUC.
2. GradientBoosting показал лучший ROC-AUC (0.9282), что подтверждает его эффективность на сложных нелинейных данных с дисбалансом.
3. Дерево решений показало скромные результаты (ROC-AUC 0.8289), что указывает на необходимость использования ансамблей для сложных задач.
4. Логистическая регрессия, несмотря на простоту, показала достойные результаты (ROC-AUC 0.8009), что может говорить о наличии линейно разделимых паттернов в данных.