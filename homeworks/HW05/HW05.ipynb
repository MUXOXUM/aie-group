{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd8471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Домашнее задание HW05 - Классификация дефолта по кредиту\n",
    "Сравнение бейзлайна и логистической регрессии\n",
    "\"\"\"\n",
    "\n",
    "# 2.3.1. Загрузка данных и первичный анализ\n",
    "\n",
    "# 1. Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix, \n",
    "    classification_report, roc_curve, precision_recall_curve, auc\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка отображения графиков\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# 2. Загрузка датасета\n",
    "df = pd.read_csv('../seminars/S05/S05-hw-dataset.csv')\n",
    "\n",
    "# 3. Анализ данных\n",
    "print(\"=\" * 60)\n",
    "print(\"1. ЗАГРУЗКА И ПЕРВИЧНЫЙ АНАЛИЗ ДАННЫХ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Первые строки\n",
    "print(\"\\nПервые 5 строк датасета:\")\n",
    "print(df.head())\n",
    "\n",
    "# Информация о столбцах и типах\n",
    "print(\"\\nИнформация о датасете:\")\n",
    "print(df.info())\n",
    "\n",
    "# Описательные статистики\n",
    "print(\"\\nОписательные статистики числовых признаков:\")\n",
    "print(df.describe().T)\n",
    "\n",
    "# Распределение целевого признака\n",
    "print(\"\\nРаспределение целевого признака 'default':\")\n",
    "target_distribution = df['default'].value_counts(normalize=True)\n",
    "print(target_distribution)\n",
    "print(f\"\\nКоличество наблюдений: {df.shape[0]}\")\n",
    "print(f\"Количество признаков: {df.shape[1] - 1} (без target)\")\n",
    "\n",
    "# Проверка на аномалии\n",
    "print(\"\\nПроверка на аномальные значения:\")\n",
    "print(f\"Минимальный возраст: {df['age'].min()}\")\n",
    "print(f\"Максимальный возраст: {df['age'].max()}\")\n",
    "print(f\"Минимальный debt_to_income: {df['debt_to_income'].min():.3f}\")\n",
    "print(f\"Максимальный debt_to_income: {df['debt_to_income'].max():.3f}\")\n",
    "print(f\"Пропущенные значения: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Визуализация распределения целевого признака\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "df['default'].value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Распределение классов дефолта')\n",
    "plt.xlabel('Дефолт (0=Нет, 1=Да)')\n",
    "plt.ylabel('Количество клиентов')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(target_distribution.values, labels=['Нет дефолта', 'Дефолт'], \n",
    "        autopct='%1.1f%%', colors=['skyblue', 'salmon'])\n",
    "plt.title('Процентное распределение классов')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/target_distribution.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Текстовые наблюдения\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"НАБЛЮДЕНИЯ:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"1. Размер датасета: 3000 наблюдений, 17 признаков (включая target)\")\n",
    "print(\"2. Целевая переменная 'default' распределена примерно 60/40%\")\n",
    "print(\"3. Явных аномалий не обнаружено: все значения в разумных диапазонах\")\n",
    "print(\"4. Пропущенных значений нет\")\n",
    "print(\"5. Все признаки числовые, что упрощает предобработку\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2.3.2. Подготовка признаков и таргета\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. ПОДГОТОВКА ПРИЗНАКОВ И ТАРГЕТА\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Выделение матрицы признаков и вектора таргета\n",
    "X = df.drop(['client_id', 'default'], axis=1)\n",
    "y = df['default']\n",
    "\n",
    "print(f\"\\nРазмерность матрицы признаков X: {X.shape}\")\n",
    "print(f\"Размерность вектора таргета y: {y.shape}\")\n",
    "print(f\"\\nНазвания признаков: {list(X.columns)}\")\n",
    "\n",
    "# Проверка диапазонов\n",
    "print(\"\\nПроверка диапазонов признаков:\")\n",
    "for col in ['debt_to_income', 'region_risk_score']:\n",
    "    print(f\"{col}: [{X[col].min():.3f}, {X[col].max():.3f}]\")\n",
    "\n",
    "# 2.3.3. Train/Test-сплит и бейзлайн-модель\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"3. РАЗДЕЛЕНИЕ ДАННЫХ И БЕЙЗЛАЙН-МОДЕЛЬ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "print(f\"Распределение классов в обучающей выборке:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nРаспределение классов в тестовой выборке:\")\n",
    "print(y_test.value_counts(normalize=True))\n",
    "\n",
    "# Создание и обучение бейзлайн-модели\n",
    "print(\"\\n--- Бейзлайн-модель ---\")\n",
    "baseline = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_baseline = baseline.predict(X_test)\n",
    "y_pred_proba_baseline = baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "roc_auc_baseline = roc_auc_score(y_test, y_pred_proba_baseline)\n",
    "\n",
    "print(f\"Стратегия бейзлайна: {baseline.strategy}\")\n",
    "print(f\"Accuracy (бейзлайн): {accuracy_baseline:.4f}\")\n",
    "print(f\"ROC-AUC (бейзлайн): {roc_auc_baseline:.4f}\")\n",
    "\n",
    "# Дополнительные метрики для бейзлайна\n",
    "print(\"\\nОтчет по классификации (бейзлайн):\")\n",
    "print(classification_report(y_test, y_pred_baseline, \n",
    "                           target_names=['No Default', 'Default']))\n",
    "\n",
    "# Объяснение бейзлайна\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ПОЯСНЕНИЕ БЕЙЗЛАЙН-МОДЕЛИ:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Бейзлайн-модель (DummyClassifier) всегда предсказывает самый частый класс (0 - нет дефолта).\")\n",
    "print(\"Это дает нам точку отсчета: любая полезная модель должна превосходить этот наивный подход.\")\n",
    "print(f\"Accuracy бейзлайна ({accuracy_baseline:.2%}) соответствует доле majority класса.\")\n",
    "print(f\"ROC-AUC бейзлайна ({roc_auc_baseline:.4f}) близок к 0.5, что ожидаемо для случайного классификатора.\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2.3.4. Логистическая регрессия и подбор гиперпараметров\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"4. ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ И ПОДБОР ГИПЕРПАРАМЕТРОВ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Создание пайплайна\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Подбор гиперпараметров с GridSearchCV\n",
    "param_grid = {\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "print(\"Подбор гиперпараметров...\")\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nЛучшие параметры: {grid_search.best_params_}\")\n",
    "print(f\"Лучшее ROC-AUC на кросс-валидации: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Обучение лучшей модели\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Предсказания на тестовой выборке\n",
    "y_pred_logreg = best_model.predict(X_test)\n",
    "y_pred_proba_logreg = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Оценка метрик\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "roc_auc_logreg = roc_auc_score(y_test, y_pred_proba_logreg)\n",
    "\n",
    "print(f\"\\n--- Лучшая модель логистической регрессии ---\")\n",
    "print(f\"Accuracy: {accuracy_logreg:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_logreg:.4f}\")\n",
    "\n",
    "# Дополнительные метрики\n",
    "print(\"\\nОтчет по классификации (логистическая регрессия):\")\n",
    "print(classification_report(y_test, y_pred_logreg, \n",
    "                           target_names=['No Default', 'Default']))\n",
    "\n",
    "# Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_pred_logreg)\n",
    "print(\"Матрица ошибок:\")\n",
    "print(cm)\n",
    "\n",
    "# Визуализация матрицы ошибок\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Default', 'Default'],\n",
    "            yticklabels=['No Default', 'Default'])\n",
    "plt.title('Матрица ошибок (Логистическая регрессия)')\n",
    "plt.ylabel('Истинные значения')\n",
    "plt.xlabel('Предсказанные значения')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/confusion_matrix.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ROC-кривая\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_logreg)\n",
    "fpr_baseline, tpr_baseline, _ = roc_curve(y_test, y_pred_proba_baseline)\n",
    "\n",
    "# Precision-Recall кривая\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba_logreg)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Визуализация ROC-кривой\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_baseline, tpr_baseline, 'b--', label=f'Бейзлайн (AUC = {roc_auc_baseline:.3f})')\n",
    "plt.plot(fpr, tpr, 'r-', label=f'Логистическая регрессия (AUC = {roc_auc_logreg:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Случайный классификатор')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Визуализация Precision-Recall кривой\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, 'g-', label=f'Логистическая регрессия (AUC = {pr_auc:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall кривая')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/roc_pr_curves.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Анализ влияния параметра C\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"АНАЛИЗ ВЛИЯНИЯ ПАРАМЕТРА C:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "c_values = results['param_logreg__C'].unique()\n",
    "c_values.sort()\n",
    "\n",
    "print(\"\\nРезультаты кросс-валидации для разных значений C:\")\n",
    "for c in c_values:\n",
    "    c_results = results[results['param_logreg__C'] == c]\n",
    "    mean_score = c_results['mean_test_score'].mean()\n",
    "    std_score = c_results['std_test_score'].mean()\n",
    "    print(f\"C = {c:6}: ROC-AUC = {mean_score:.4f} (+/- {std_score:.4f})\")\n",
    "\n",
    "print(\"\\nНаблюдения:\")\n",
    "print(\"1. Слишком маленькие C (сильная регуляризация) ухудшают качество\")\n",
    "print(\"2. Слишком большие C (слабая регуляризация) могут привести к переобучению\")\n",
    "print(\"3. Оптимальное значение C = 1 (уравновешивает bias-variance tradeoff)\")\n",
    "\n",
    "# 2.3.5. Сравнение бейзлайна и логистической регрессии\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"5. СРАВНЕНИЕ МОДЕЛЕЙ И ВЫВОДЫ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Создание таблицы сравнения\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['DummyClassifier (Most Frequent)', 'Logistic Regression'],\n",
    "    'Accuracy': [accuracy_baseline, accuracy_logreg],\n",
    "    'ROC-AUC': [roc_auc_baseline, roc_auc_logreg],\n",
    "    'Improvement (Accuracy)': ['-', f'+{(accuracy_logreg - accuracy_baseline) * 100:.1f}%'],\n",
    "    'Improvement (ROC-AUC)': ['-', f'+{(roc_auc_logreg - roc_auc_baseline) * 100:.1f}%']\n",
    "})\n",
    "\n",
    "print(\"\\nСравнение моделей:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Визуализация сравнения\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Сравнение Accuracy\n",
    "axes[0].bar(['Бейзлайн', 'Логистическая регрессия'], \n",
    "           [accuracy_baseline, accuracy_logreg], \n",
    "           color=['skyblue', 'salmon'])\n",
    "axes[0].set_title('Сравнение Accuracy')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_ylim(0, 1)\n",
    "for i, v in enumerate([accuracy_baseline, accuracy_logreg]):\n",
    "    axes[0].text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "# Сравнение ROC-AUC\n",
    "axes[1].bar(['Бейзлайн', 'Логистическая регрессия'], \n",
    "           [roc_auc_baseline, roc_auc_logreg], \n",
    "           color=['skyblue', 'salmon'])\n",
    "axes[1].set_title('Сравнение ROC-AUC')\n",
    "axes[1].set_ylabel('ROC-AUC')\n",
    "axes[1].set_ylim(0, 1)\n",
    "for i, v in enumerate([roc_auc_baseline, roc_auc_logreg]):\n",
    "    axes[1].text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/model_comparison.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Текстовый отчет\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ТЕКСТОВЫЙ ОТЧЕТ\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. КРАТКОЕ СРАВНЕНИЕ МОДЕЛЕЙ:\n",
    "\n",
    "   Бейзлайн-модель (DummyClassifier) показала accuracy 59.6%, что соответствует \n",
    "   доле majority класса (клиентов без дефолта). ROC-AUC бейзлайна составляет 0.500, \n",
    "   что характерно для случайного классификатора.\n",
    "\n",
    "   Логистическая регрессия значительно превзошла бейзлайн:\n",
    "   - Accuracy увеличилась на 20.0% (с 59.6% до 79.6%)\n",
    "   - ROC-AUC увеличился на 29.0% (с 0.500 до 0.790)\n",
    "\n",
    "2. ВЛИЯНИЕ РЕГУЛЯРИЗАЦИИ:\n",
    "\n",
    "   Подбор параметра C показал, что:\n",
    "   - При C=0.001 (сильная регуляризация) модель недообучается\n",
    "   - При C=100 (слабая регуляризация) есть риск переобучения\n",
    "   - Оптимальное значение C=1 обеспечивает баланс между bias и variance\n",
    "\n",
    "3. ВЫВОДЫ И РЕКОМЕНДАЦИИ:\n",
    "\n",
    "   а) Логистическая регрессия демонстрирует хорошее качество на данной задаче,\n",
    "      значительно превосходя бейзлайн по обеим метрикам.\n",
    "\n",
    "   б) ROC-AUC = 0.790 указывает на хорошую разделяющую способность модели.\n",
    "\n",
    "   в) Для данной задачи (предсказание дефолта по кредиту) логистическая регрессия\n",
    "      является разумным выбором благодаря:\n",
    "      - Интерпретируемости коэффициентов\n",
    "      - Хорошему балансу точности и полноты\n",
    "      - Устойчивости к умеренному дисбалансу классов (60/40%)\n",
    "\n",
    "   г) Для дальнейшего улучшения модели можно рассмотреть:\n",
    "      - Борьбу с дисбалансом классов (SMOTE, классовые веса)\n",
    "      - Добавление полиномиальных признаков\n",
    "      - Использование более сложных алгоритмов (случайный лес, градиентный бустинг)\n",
    "\"\"\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Сохранение важных коэффициентов модели\n",
    "if hasattr(best_model.named_steps['logreg'], 'coef_'):\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'coefficient': best_model.named_steps['logreg'].coef_[0],\n",
    "        'abs_coefficient': np.abs(best_model.named_steps['logreg'].coef_[0])\n",
    "    }).sort_values('abs_coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nТоп-10 самых важных признаков:\")\n",
    "    print(coef_df.head(10).to_string(index=False))\n",
    "    \n",
    "    # Визуализация важности признаков\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features = coef_df.head(10).sort_values('coefficient', ascending=True)\n",
    "    plt.barh(top_features['feature'], top_features['coefficient'], \n",
    "            color=['red' if x < 0 else 'green' for x in top_features['coefficient']])\n",
    "    plt.xlabel('Коэффициент (влияние на вероятность дефолта)')\n",
    "    plt.title('Топ-10 самых важных признаков для предсказания дефолта')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/feature_importance.png', dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ВСЕ ГРАФИКИ СОХРАНЕНЫ В ПАПКУ 'figures/'\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
