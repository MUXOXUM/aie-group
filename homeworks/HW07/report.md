# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

1. S07-hw-dataset-01.csv
2. S07-hw-dataset-02.csv
3. S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 столбцов (1 идентификатор + 8 признаков)
- Признаки: 8 числовых признаков (f01-f08), все в формате float64
- Пропуски: нет пропусков во всех признаках
- "Подлости" датасета: Признаки в разных шкалах (значения от -100 до 100), что требует обязательного масштабирования. Также содержит шумовые признаки, которые могут мешать кластеризации.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 4000 строк, 4 столбца (1 идентификатор + 3 признака)
- Признаки: 3 числовых признака (x1, x2, z_noise), все в формате float64
- Пропуски: нет пропусков
- "Подлости" датасета: Нелинейная структура данных, наличие выбросов, шумовой признак z_noise, который добавляет лишнюю размерность.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 5000 строк, 5 столбцов (1 идентификатор + 4 признака)
- Признаки: 4 числовых признака (x1, x2, f_corr, f_noise), все в формате float64
- Пропуски: нет пропусков
- "Подлости" датасета: Кластеры разной плотности, наличие фонового шума, коррелированные признаки (f_corr), что создает проблемы для алгоритмов, предполагающих равномерную плотность.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг**: 
  - Для всех датасетов: масштабирование числовых признаков с помощью `StandardScaler`
  - Проверка на пропуски
  - Категориальных признаков нет, поэтому кодирование не требовалось
  - PCA использовался только для визуализации (2 компоненты)

- **Поиск гиперпараметров**:
  - **KMeans**: Диапазон k = 2-20 для dataset-01, 2-10 для dataset-02, 2-15 для dataset-03
  - **DBSCAN**: eps = 0.1-2.0 для dataset-01, eps = 0.1-1.0 для dataset-03; min_samples = [2, 3, 5, 10]
  - **AgglomerativeClustering**: k = 2-10; linkage = ['ward', 'complete', 'average', 'single']
  - При выборе "лучшего" руководствовались максимизацией silhouette score при разумных условиях (не слишком много шума для DBSCAN, не слишком много кластеров)

- **Метрики**: 
  - silhouette_score, davies_bouldin_score, calinski_harabasz_score для всех методов
  - Для DBSCAN: метрики вычислялись только на non-noise точках (labels != -1)
  - Для DBSCAN также фиксировалась доля шума (noise_ratio)

- **Визуализация**:
  - PCA для всех датасетов с фиксированным random_state=42
  - Графики silhouette vs k для KMeans
  - Графики silhouette vs eps для DBSCAN
  - Сравнение linkage методов для AgglomerativeClustering

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

**Датасет S07-hw-dataset-01**:
- KMeans: k = 2-20, random_state=42, n_init=10
- DBSCAN: eps = 0.1-2.0 (20 значений), min_samples = [2, 3, 5, 10]

**Датасет S07-hw-dataset-02**:
- KMeans: k = 2-10, random_state=42, n_init=10
- AgglomerativeClustering: k = 2-10, linkage = ['ward', 'complete', 'average', 'single']

**Датасет S07-hw-dataset-03**:
- KMeans: k = 2-15, random_state=42, n_init=10
- DBSCAN: eps = 0.1-1.0 (20 значений), min_samples = [2, 3, 5, 7, 10]

## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: **KMeans** с k=8
- Метрики: silhouette=0.2977, DB=1.0265, CH=6307.23
- DBSCAN показал долю шума 0.086 при eps=0.3, min_samples=5, но silhouette=0.1537 (хуже KMeans)
- **Почему решение разумное**: Датасет имеет признаки в разных шкалах, но после масштабирования KMeans хорошо справляется благодаря предположительно сферической форме кластеров. DBSCAN проигрывает из-за равномерной плотности кластеров.

### 4.2 Dataset B

- Лучший метод и параметры: **AgglomerativeClustering** с k=2, linkage='complete'
- Метрики: silhouette=0.5866, DB=0.6981, CH=4392.61
- KMeans с k=2 показал silhouette=0.4391 (хуже Agglomerative)
- **Почему решение разумное**: Нелинейная структура данных с выбросами. AgglomerativeClustering с complete linkage лучше справляется с такими структурами, так как не предполагает сферичности кластеров, в отличие от KMeans.

### 4.3 Dataset C

- Лучший метод и параметры: **DBSCAN** с eps=0.4, min_samples=3
- Метрики (на non-noise точках): silhouette=0.6421, DB=0.4064, CH=1582.39
- Доля шума: 14.1%
- Количество найденных кластеров: 4
- **Почему решение разумное**: Датасет содержит кластеры разной плотности и фоновый шум. DBSCAN идеально подходит для таких случаев, так как автоматически определяет плотностные кластеры и выделяет шум. KMeans не справляется с разной плотностью (silhouette=0.4185).

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"** в случаях:
  - Нелинейных структур (dataset-02) - из-за предположения о сферичности кластеров
  - Разной плотности кластеров (dataset-03) - не может корректно разделить плотные и разреженные области
  - Наличия выбросов - сильно влияет на положение центроидов

- **DBSCAN/иерархическая кластеризация выигрывают**:
  - DBSCAN: при разной плотности кластеров и наличии шума (dataset-03)
  - AgglomerativeClustering: при нелинейных структурах (dataset-02), особенно с complete linkage

- **Что сильнее всего влияло на результат**:
  1. **Масштабирование**: критически важно для dataset-01 с разными шкалами признаков
  2. **Плотность кластеров**: главный фактор для выбора между KMeans и DBSCAN
  3. **Выбросы**: влияют на KMeans, но хорошо обрабатываются DBSCAN (как шум)

### 5.2 Устойчивость (обязательно для одного датасета)

- **Проверка устойчивости**: Для dataset-01 выполнено 5 запусков KMeans с разными random_state (0, 10, 20, 30, 40)
- **Результаты**: 
  - Средний Adjusted Rand Index (ARI) между запусками: 0.9978
  - Стандартное отклонение ARI: 0.0014
  - Inertia различалась незначительно (разница < 0.5%)
- **Вывод**: KMeans показал высокую устойчивость на этом датасете. Это связано с хорошо разделенными, компактными кластерами после масштабирования. Разные инициализации приводят к практически идентичным разбиениям.

### 5.3 Интерпретация кластеров

- **Метод интерпретации**: Анализ центроидов кластеров для dataset-01 (KMeans, k=8)
- **Наблюдения**:
  - Кластер 0: низкие значения f01-f03, высокие f04-f05
  - Кластер 1: высокие f01, f02, f06, низкие f04, f07
  - Кластер 2: средние значения по всем признакам
  - Кластер 3: экстремально высокие f07, низкие f05
  - Кластеры 4-7: различные комбинации высоких/низких значений разных признаков
- **Выводы**:
  1. Кластеры хорошо дифференцируются по нескольким признакам одновременно
  2. Некоторые кластеры характеризуются экстремальными значениями отдельных признаков
  3. Есть кластер со средними значениями, вероятно, представляющий "типичные" наблюдения
  4. Распределение по кластерам относительно равномерное (12-15% каждый)

## 6. Conclusion

1. **Масштабирование обязательно** для признаков в разных шкалах - без него результаты кластеризации не имеют смысла.

2. **Выбор алгоритма зависит от структуры данных**: 
   - KMeans - для сферических кластеров схожей плотности
   - DBSCAN - для кластеров разной плотности и обнаружения шума
   - AgglomerativeClustering - для нелинейных структур

3. **Метрики нуждаются в осторожной интерпретации**: silhouette не всегда определяет "лучшее" с точки зрения бизнес-логики, особенно для DBSCAN с шумом.

4. **Устойчивость KMeans зависит от данных**: при хорошо разделенных кластерах алгоритм устойчив, при перекрывающихся - чувствителен к инициализации.

5. **DBSCAN требует тщательного подбора параметров**: особенно eps, который сильно зависит от масштаба данных после препроцессинга.

6. **Препроцессинг определяет успех**: корректная обработка данных важнее выбора алгоритма.

7. **Эксперимент должен быть воспроизводимым**: фиксация random_state, использование pipeline, сохранение артефактов.
